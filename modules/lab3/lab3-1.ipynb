{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3-1:  Non-Parametric Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sign Test\n",
    "\n",
    "The sign test can be used if we have a sample dataset and want to know if the mean of this dataset is different from some null hypothesis mean, $\\mu$.\n",
    "\n",
    "We first calculate the anomaly for each number in our dataset, which is the difference between that number and the null hypothesis mean:\n",
    "\n",
    "$anomaly = (x - \\mu)$\n",
    "\n",
    "If our samples came from a population with a mean of $\\mu$, then we'd expect to have appoximately equal numbers of positive and negative anomalies. In other words, if the null hypothesis is true, weâ€™d expect our sample values to fall evenly on either side of the null hypothesis mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis is that our sample mean is equal to some population mean, and stated formally is:\n",
    "\n",
    "$H_0: \\bar{x} = \\mu$\n",
    "\n",
    "The test statistic we use in the sign test is the number of samples that are larger than $\\mu$, which is the number of positive anomalies.\n",
    "\n",
    "$y = $ count of anomalies $ > 0$\n",
    "\n",
    "We can have one-sided or two-sided alternate hypotheses:\n",
    "\n",
    "| Alternate Hypothesis | Rejection Region |\n",
    "| --- | --- |\n",
    "|$H_{a}: \\bar{x} > \\mu$ | $y \\geq c$ |\n",
    "|$H_{a}: \\bar{x} < \\mu$ |  $y \\leq c$ |\n",
    "|$H_{a}: \\bar{x} \\neq \\mu$ |  $y \\geq c$ or  $y \\leq n - c$ |\n",
    "\n",
    "The \"critical number\", $c$ that defines our rejection region come from the binomial distribution (with 50% probability), and $\\alpha$ (or $\\frac{\\alpha}{2}$ for a two-sided test) for our chosen confidence level.\n",
    "\n",
    "We use a binomial distribution with probability of 50% because for our null hypothesis to be true, about 50% of our anomalies should be positive, and about 50% should be negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The critical number, $c$, that defines our rejection region can be looked up in a binomial distribution table (corresponding to the sample size, $n$, for the test), or in python we can use a function like `scipy.binom.ppf()` ([read the documentation for this function here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html)) (and remember to set p=0.5 for 50% probability)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try this our below with an example:\n",
    "\n",
    "Suppose we took measurements of [turbidity](https://en.wikipedia.org/wiki/Turbidity) during and just after a storm event in some natural stream, and we want to determine if the mean turbitity exceeded 100 NTU.\n",
    "\n",
    "Our measurements are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset\n",
    "x = np.array( [50, 70, 170, 50, 170, 30, 170, 140, 130, 200, 90, 70, 10, 80, 230, 190, 110, 140, 20, 110, ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our null hypothesis is:\n",
    "\n",
    "$H_0: \\bar{x} = \\mu = 100$ NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null hypothesis mean\n",
    "mu = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our alternate hypothesis is:\n",
    "\n",
    "$H_{a}: \\bar{x} > \\mu$ or $\\bar{x} > 100$ NTU \n",
    "\n",
    "With rejection region $y \\geq c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute our test statistic, we need to first compute the anomalies: $(x - \\mu)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-50, -30,  70, -50,  70, -70,  70,  40,  30, 100, -10, -30, -90,\n",
       "       -20, 130,  90,  10,  40, -80,  10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate anomalies\n",
    "anomalies = x - mu\n",
    "\n",
    "# look at the anomalies\n",
    "anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, count the number of positive anomalies. One way to do this in python is to use a [boolean](https://www.w3schools.com/python/python_booleans.asp) array of True/False values, and take the sum. Python treats True values as a 1, and False values as a 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False,  True, False,  True,  True,  True,\n",
       "        True, False, False, False, False,  True,  True,  True,  True,\n",
       "       False,  True])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_anomalies = anomalies > 0\n",
    "\n",
    "# Look at our boolean array, each \"true\" corresponds to a positive anomaly\n",
    "positive_anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the `numpy.sum()` function, it will treat each True as a 1, and each False as a 0, therefore we get the county of positive anomalies only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of positive anomalies, this is our test statistic\n",
    "y = np.sum( anomalies > 0 )\n",
    "\n",
    "# look at our test statistic\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to find our critical value, $c$, to see if we can accept or reject the null hypothesis.\n",
    "\n",
    "$c$ comes from a binomial distribution, with $n$ being our number of samples, and a probability of 50%.\n",
    "\n",
    "This is also where we get to choose the level of confidence, our alpha, for our test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic, y = 11\n",
      "Critical value, c = 6.0\n"
     ]
    }
   ],
   "source": [
    "# Choose my alpha for 95% confidence, one-sided test\n",
    "alpha = 0.05\n",
    "# Number of samples is the length of x\n",
    "n =len(x)\n",
    "\n",
    "# Compute the critical value from the binomial distribution (with p=50%)\n",
    "c = stats.binom.ppf(alpha, n, 0.5)\n",
    "\n",
    "# Can I reject the null hypothesis?\n",
    "print('Test statistic, y = {}'.format(y))\n",
    "print('Critical value, c = {}'.format(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test statistic exceeds our critical value, therefore we are in the rejection region for this one-sided sign test ($y \\geq c$) and can reject the null hypothesis.\n",
    "\n",
    "The mean turbidity of the stream at this time was greater than 100 NTU, with 95% confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, note that the sign test does not take into account the **magnitude** of the anomalies..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Rank-Sum Test\n",
    "\n",
    "The [Rank-Sum Test](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test) (also called the Mann-Whitney U test, or Wilcoxon Rank-sum Test) is a non-parametric test that lets us determine if one group of measurements is larger than a second group. Unlike the parametric tests we've used previously, we do not need to assume normality (or any particular distribution), nor that the two groups have similar distributions, nor that the two groups have equal variances.\n",
    "\n",
    "The null hypothesis is that the probability of any given sample from one group, $x_i$, being greater than samples from the other group, $y_j$, is only 50%. In other words, the null hypothesis is that the probability of samples from one group being higher or lower than samples from the other group are equal (both 50%).\n",
    "\n",
    "$H_0: P(x_i > y_j) = 0.5$\n",
    "\n",
    "We can have alternative hypotheses for one- and two-sided tests:\n",
    "\n",
    "$H_a: P(x_i > y_j) \\leq 0.5$ (we are testing if x is smaller than y)\n",
    "\n",
    "$H_a: P(x_i > y_j) \\geq 0.5$ (we are testing if x is larger than y)\n",
    "\n",
    "$H_a: P(x_i > y_j) \\neq 0.5$ (we are testing if x is different than y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to rank all of our data. If we have one group of length $n$ with samples $x_i$, and another group with length $m$ with sample $y_j$, we sort the data from low to high, and assign the \"joint ranks\" $R_k$ for each data point where:\n",
    "\n",
    "$R_k = 1 ... (N = n + m)$\n",
    "\n",
    "The idea is that if we expect our null hypothesis to be true, then we should have equal numbers of \"low rank\" $x_i$ and $y_j$ values, and equal numbers of \"high rank\" $x_i$ and $y_j$ values.  If we have a tie anywhere, use the average rank.\n",
    "\n",
    "The test statistic is then the sum of ranks for one of the groups (if groups have different sample sizes, use the group with the smaller sample size):\n",
    "\n",
    "$W_{rs} = \\sum R_{i}$ or $\\sum R_{j}$ \n",
    "\n",
    "We can reject the null hypothesis when our test statistic falls in the rejection region defined by critical values we can  look up in a [table](http://plantsys.elte.hu/oktatas/Biometria/tablazatok/Wilcoxon_table_ketmintas_probahoz.pdf), given our sample sizes $n$ and $m$, and chosen significance level with $alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other rank-sum test statistics:**\n",
    "\n",
    "The test statistic, $W$ is nearly normally distributed with even small sample sizes (Section [5.1.4 The Large-sample Approximation to the Rank-sum Test](https://pubs.usgs.gov/tm/04/a03/tm4a3.pdf)). The \"large-sample approximation\" method uses a \"continuity correction\" to shift $W_{rs}$ values by $d/2$ where $d$ is the smallest possible difference between $W_{rs}$ values (for the rank-sum test, $d=1$). This can then be expressed as the test statistic $Z_{rs}$:\n",
    "\n",
    "$Z_{rs} = \\displaystyle\\frac{W_{rs}\\pm\\frac{1}{2}-\\frac{1}{2}\\cdot n\\cdot (n+m+1)}{\\sqrt{n\\cdot m\\cdot(n+m+1)\\cdot\\frac{1}{12}}}$\n",
    "\n",
    "where the $\\pm$ refers to whether we are making a one sided test with a posited increase or decrease (where if we're looking for an increase, adjust down, subtract, or if we're looking for a decrease, adjust up, add).  See equation 5.3 in Chapter 5 (Section [5.1.4 The Large-sample Approximation to the Rank-sum Test](https://pubs.usgs.gov/tm/04/a03/tm4a3.pdf)).\n",
    "\n",
    "Note also that you will also somtimes see the U test statistic used here, as in the \"Mann-Whitney U test\", where $U = W_{rs} - \\displaystyle \\frac{n(n+1)}{2}$ (here is a [table](https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Nonparametric/Mann-Whitney-Table-CriticalValues.pdf) with U statistic values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "In the example below, we measure 10 samples of turbidity in two streams (group $x$ with $n=10$ and group $y$ with $m=10$), and we want to know if they are different from one another (two-tailed test) with 95% confidence, $\\alpha=0.05$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample datasets (there are no ties in this data, so we don't need to worry about it in this example)\n",
    "x = np.array( [155, 70, 175, 50, 190, 115, 195, 140, 215, 200 ] )\n",
    "y = np.array( [100, 40, 65, 25, 90, 30, 10, 75, 130, 110 ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dataframe to store our values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>155</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>115</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>195</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>140</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>215</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x    y\n",
       "0  155  100\n",
       "1   70   40\n",
       "2  175   65\n",
       "3   50   25\n",
       "4  190   90\n",
       "5  115   30\n",
       "6  195   10\n",
       "7  140   75\n",
       "8  215  130\n",
       "9  200  110"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'x': x, 'y': y})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot to format the table with group labels and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>x</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>x</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>x</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>x</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>x</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>y</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>y</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>y</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>y</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>y</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>y</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>y</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>y</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>y</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>y</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group  value\n",
       "0      x    155\n",
       "1      x     70\n",
       "2      x    175\n",
       "3      x     50\n",
       "4      x    190\n",
       "5      x    115\n",
       "6      x    195\n",
       "7      x    140\n",
       "8      x    215\n",
       "9      x    200\n",
       "10     y    100\n",
       "11     y     40\n",
       "12     y     65\n",
       "13     y     25\n",
       "14     y     90\n",
       "15     y     30\n",
       "16     y     10\n",
       "17     y     75\n",
       "18     y    130\n",
       "19     y    110"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.melt(df, value_vars=['x', 'y'], var_name='group', value_name='value')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the data by value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>y</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>y</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>y</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>x</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>y</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>y</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>y</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>y</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>x</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>y</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>x</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>x</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>x</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>x</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>x</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>x</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>x</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group  value\n",
       "0      y     10\n",
       "1      y     25\n",
       "2      y     30\n",
       "3      y     40\n",
       "4      x     50\n",
       "5      y     65\n",
       "6      x     70\n",
       "7      y     75\n",
       "8      y     90\n",
       "9      y    100\n",
       "10     y    110\n",
       "11     x    115\n",
       "12     y    130\n",
       "13     x    140\n",
       "14     x    155\n",
       "15     x    175\n",
       "16     x    190\n",
       "17     x    195\n",
       "18     x    200\n",
       "19     x    215"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sorted = data.sort_values('value', ignore_index=True)\n",
    "data_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a rank to each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>value</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>y</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>y</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>y</td>\n",
       "      <td>65</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>x</td>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>y</td>\n",
       "      <td>75</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>y</td>\n",
       "      <td>90</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>y</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>y</td>\n",
       "      <td>110</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>x</td>\n",
       "      <td>115</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>y</td>\n",
       "      <td>130</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>x</td>\n",
       "      <td>140</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>x</td>\n",
       "      <td>155</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>x</td>\n",
       "      <td>175</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>x</td>\n",
       "      <td>190</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>x</td>\n",
       "      <td>195</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>x</td>\n",
       "      <td>200</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>x</td>\n",
       "      <td>215</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group  value  rank\n",
       "0      y     10     1\n",
       "1      y     25     2\n",
       "2      y     30     3\n",
       "3      y     40     4\n",
       "4      x     50     5\n",
       "5      y     65     6\n",
       "6      x     70     7\n",
       "7      y     75     8\n",
       "8      y     90     9\n",
       "9      y    100    10\n",
       "10     y    110    11\n",
       "11     x    115    12\n",
       "12     y    130    13\n",
       "13     x    140    14\n",
       "14     x    155    15\n",
       "15     x    175    16\n",
       "16     x    190    17\n",
       "17     x    195    18\n",
       "18     x    200    19\n",
       "19     x    215    20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sorted['rank'] = data_sorted.index + 1\n",
    "data_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute our test statistic, $W_{rs} = \\sum R_{i}$ for $i=1,...,n$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic, W = 143\n"
     ]
    }
   ],
   "source": [
    "W = data_sorted.loc[data_sorted.group=='x']['rank'].sum()\n",
    "print('Test statistic, W = {}'.format(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look up our critical W values in this [table](http://plantsys.elte.hu/oktatas/Biometria/tablazatok/Wilcoxon_table_ketmintas_probahoz.pdf), and find that for a 2-tailed test, with $\\alpha=0.05$ and sample sizes $n=10$ and $m=10$, the upper and lower critical values are:\n",
    "\n",
    "$W_{c,l}=78$\n",
    "\n",
    "$W_{c,u}=132$\n",
    "\n",
    "Our result is that $W_{rs} > W_{c,u}$, our test statistic is greater than the upper critical value. Therefore we can reject the null hypothesis, and say that our alternate hypothesis that group $x$ has higher turbidity than group $y$ is true with 95% confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also compute the test statistic $U = W_{rs} - \\displaystyle \\frac{n(n+1)}{2}$\n",
    "\n",
    "(We can look up the critical U values in this [table](https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Nonparametric/Mann-Whitney-Table-CriticalValues.pdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic, U = 88.0\n"
     ]
    }
   ],
   "source": [
    "n = len(x)\n",
    "U = W - (n*(n+1))/2\n",
    "print('Test statistic, U = {}'.format(U))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the test \"large-sample approximation\" test statistic $Z_{rs} = \\displaystyle\\frac{W_{rs}\\pm\\frac{1}{2}-\\frac{1}{2}\\cdot n\\cdot (n+m+1)}{\\sqrt{n\\cdot m\\cdot(n+m+1)\\cdot\\frac{1}{12}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test statistic, Z = 2.834733547569204\n"
     ]
    }
   ],
   "source": [
    "n = len(x)\n",
    "m = len(y)\n",
    "\n",
    "Z = (W - 0.5 - 0.5*n*(n+m+1)) / np.sqrt( n*m*(n+m+1)/12 )\n",
    "print('Test statistic, Z = {}'.format(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "What does it look like if we pick the other group? (since our groups are the same size, we could pick either one to look at)\n",
    "\n",
    "**Compute the rank-sum test statistics W, U, and Z using the ranks of the other group, $y$**\n",
    "\n",
    "So in this case our alternate hypothesis is $H_a: P(y_j > x_i) \\neq 0.5$\n",
    "\n",
    "Do we come to the same conclusion (reject the null hypothesis) as above? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Investigating python functions:\n",
    "\n",
    "What functions are available to us in python to perform a rank-sum test?\n",
    "\n",
    "The scipy library has two we can investigate:\n",
    "* [scipy.stats.ranksums](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ranksums.html)\n",
    "* [scipy.stats.mannwhitneyu](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html)\n",
    "\n",
    "Read the documentation for both of these functions, and try them out with our sample datasets ($x$ and $y$) in the rank-sum test example above. \n",
    "\n",
    "Also take a look at the source code for each function to identify the equations they are using.\n",
    "\n",
    "Then try to answer the following questions:\n",
    "\n",
    "1. What assumptions are these functions making? \n",
    "2. Are there any additional inputs/options we need to specify to make sure that they duplicate our results above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
